---
  title: OpenAI
  description: Додаток Blackbird OpenAI
---
import { LinkCard } from "@astrojs/starlight/components";

<LinkCard title="View on Github" target="_blank" href="https://github.com/bb-io/OpenAI" icon="github" />

Цей додаток OpenAI у Blackbird надає вам доступ до всіх кінцевих точок API та моделей, які пропонує OpenAI, від завершення, чату, редагування до генерації зображень DALL-E та Whisper.

## Перед налаштуванням

Перш ніж підключитись, переконайтеся, що:

- У вас є [обліковий запис OpenAI](https://platform.openai.com/signup).
- Ви згенерували новий ключ API в розділі [API keys](https://platform.openai.com/account/api-keys), що надає програмний доступ до моделей OpenAI на основі оплати за використання. Таким чином, ви платите лише за фактичне використання, яке [починається з $0,002 за 1000 токенів](https://openai.com/pricing) для найшвидшої моделі чату. Зауважте, що план підписки ChatGPT Plus для цього не підходить; він надає доступ лише до обмеженого веб-інтерфейсу на chat.openai.com і не включає доступ до API OpenAI. Переконайтеся, що ви скопіювали весь ключ API, який відображається один раз при створенні, а не скорочену версію. Ключ API має вигляд `sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`.
- Ваш обліковий запис API має спосіб оплати та позитивний баланс, не менше $5. Ви можете налаштувати це в розділі [Billing settings](https://platform.openai.com/account/billing/overview).

**Примітка**: За замовчуванням Blackbird використовує найновіші моделі у своїх діях. Якщо ваша підписка не підтримує ці моделі, вам доведеться додати моделі, які ви можете використовувати, до кожної дії Blackbird.

## Підключення

1. Перейдіть до додатків і знайдіть OpenAI.
2. Натисніть _Add Connection_.
3. Назвіть своє підключення для подальшого використання, наприклад, "Моє підключення OpenAI".
4. Введіть отриманий раніше ключ API.
5. Натисніть _Connect_.

![1694611695232](https://raw.githubusercontent.com/bb-io/OpenAI/main/image/README/1694611695232.png)

## Actions

Усі текстові дії мають такі додаткові вхідні значення для зміни згенерованої відповіді:

- Model (за замовчуванням найновіша)
- Maximum tokens
- Temperature
- top_p
- Presence penalty
- Frequency penalty

Для більш детальної інформації про більшість дій зверніться до [OpenAI API reference](https://platform.openai.com/docs/api-reference).

Різні дії підтримують різні моделі, які підходять для конкретного завдання (наприклад, модель gpt-4 для дії **Chat**). Групи дій та відповідні моделі, рекомендовані для них, показані в таблиці нижче.

| Група дій | Найновіші моделі | Модель за замовчуванням (коли параметр вводу _Model ID_ не вказано) | Застарілі моделі |
| :----------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| Chat | gpt-4o, gpt-o1, gpt-o1 mini, gpt-4-turbo-preview та датовані випуски моделей, gpt-4 та датовані випуски моделей, gpt-4-vision-preview, gpt-4-32k та датовані випуски моделей, gpt-3.5-turbo та датовані випуски моделей, gpt-3.5-turbo-16k та датовані випуски моделей, доналаштовані версії gpt-3.5-turbo | gpt-4-turbo-preview; gpt-4-vision-preview для дії **Chat with image** | gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-3.5-turbo-0301, gpt-4-0314, gpt-4-32k-0314 |
| Audiovisual | Для транскрипцій та перекладів підтримується лише whisper-1. Для створення мовлення підтримуються tts-1 та tts-1-hd. | tts-1-hd для дії **Create speech** | - |
| Images | dall-e-2, dall-e-3 | dall-e-3 | - |
| Embeddings | text-embedding-ada-002 | text-embedding-ada-002 | text-similarity-ada-001, text-similarity-babbage-001, text-similarity-curie-001, text-similarity-davinci-001, text-search-ada-doc-001, text-search-ada-query-001, text-search-babbage-doc-001, text-search-babbage-query-001, text-search-curie-doc-001, text-search-curie-query-001, text-search-davinci-doc-001, text-search-davinci-query-001, code-search-ada-code-001, code-search-ada-text-001, code-search-babbage-code-001, code-search-babbage-text-001 |

Ви можете звернутися до документації [Models](https://platform.openai.com/docs/models), щоб знайти інформацію про доступні моделі та відмінності між ними.

Деякі запропоновані дії попередньо сконструйовані поверх OpenAI. Це означає, що вони розширюють кінцеві точки OpenAI додатковим інженерним підходом до промпту для загальних мовних операцій та операцій з контентом.

У вас є цікавий варіант використання, який ми можемо перетворити на дію? Дайте нам знати!

### Chat

- **Chat** дає відповідь на повідомлення чату. За бажанням ви можете додати системний промпт та/або зображення. Також ви можете додати колекцію текстів, і вона буде додана до промпту разом із повідомленням. Також можна додати Glossary. Корисно, якщо ви хочете додати колекцію повідомлень до промпту.
- **Chat with system prompt** те саме, що й вище, за винятком того, що системний промпт є обов'язковим.

### Assistant

- **Message assistant** надсилає повідомлення попередньо налаштованому асистенту. Він виконає асистента та поверне його повідомлення. Дія асистента може приймати до 10 файлів у якості введення. **Примітка**: Якщо ви хочете прочитати прикріплені файли, переконайтеся, що у вашого асистента увімкнено _Retrieval_.

### Localization (pre-engineered)

- **Post-edit MT** отримавши вихідний сегмент та цільовий сегмент, перекладений за допомогою нейромережевого машинного перекладу, відповідає відредагованою версією цільового сегмента з урахуванням типових помилок нейромережевого машинного перекладу.
- **Get translation issues** отримавши вихідний сегмент та цільовий сегмент, перекладений за допомогою нейромережевого машинного перекладу, виділяє потенційні проблеми перекладу. Може використовуватися для попереднього заповнення коментарів сегментів у TMS.
- **Get MQM report** виконує LQA-аналіз перекладу. Результат буде у вигляді MQM-фреймворку. Вимірювання: термінологія, точність, мовні конвенції, стиль, регіональні конвенції, відповідність аудиторії, дизайн та розмітка. Вхідні дані складаються з вихідного та перекладеного тексту. За бажанням можна додати мови та опис цільової аудиторії.
- **Get MQM dimension values** використовує ті самі вхідні дані та промпт, що й "Get MQM report". Однак у цій дії оцінки повертаються як окремі числа, щоб їх можна було використовувати для прийняття рішень. Також повертає запропонований переклад.
- **Translate text** отримавши текст та локаль, намагається створити локалізовану версію тексту.

- **Get localizable content from image** отримує локалізований вміст із заданого зображення.

### Content repurposing

Усі дії можуть використовувати: Target audience, locale, glossary, tone of voice та будь-які додаткові промпти

- **Repurpose content** переробляє контент для конкретної цільової аудиторії.
- **Summarize content** створює резюме контенту.

### Glossary extraction

- **Extract glossary** витягує глосарій (.tbx) з будь-якого (багатомовного) контенту. Ви можете використовувати його у поєднанні з іншими додатками, які використовують глосарії.

### Audiovisual

- **Create transcription** транскрибує підтримувані аудіовізуальні формати файлів у текстову відповідь.
- **Create English translation** те саме, що й вище, але автоматично перекладається англійською.
- **Create speech** генерує аудіо з текстового введення.

### Images

- **Generate image** використовуйте DALL-E для генерування зображення на основі промпту.

### Other

- **Create embedding** створює векторне вкладення тексту. Корисно у поєднанні з векторними базами даних, такими як Pinecone, для зберігання великих наборів даних.
- **Tokenize text** перетворює текст на токени. Використовує Tiktoken під капотом.

### XLIFF operations

Усі дії XLIFF підтримують версії 1.2 та 2.1 формату XLIFF, оскільки це найпоширеніші версії, які використовуються в галузі, але якщо вам потрібна підтримка інших версій, будь ласка, зв'яжіться з нами, і ми розглянемо можливість додавання підтримки для них.

Наразі ми використовуємо функцію [structured output](https://platform.openai.com/docs/guides/structured-outputs/structured-outputs) для повернення результатів дій. Це означає, що вихідні дані дій будуть структуровані таким чином, щоб їх було легко аналізувати, і це може підвищити стабільність дій. Однак зауважте, що `Structured Outputs` доступні в останніх великих мовних моделях, починаючи з GPT-4o:
- gpt-4o-mini-2024-07-18 та пізніші
- gpt-4o-2024-08-06 та пізніші
<br/>

Ви можете знайти більше інформації про структуровані виходи в [документації OpenAI](https://platform.openai.com/docs/guides/structured-outputs/introduction).

- **Get Quality Scores for XLIFF file** Отримує показники якості на рівні сегментів та файлів для файлів XLIFF. За бажанням ви можете додати параметри введення Threshold, New Target State та Condition до дії Blackbird, щоб змінити значення цільового стану сегментів, які відповідають бажаним критеріям (усі три повинні бути заповнені).

    Додаткові вхідні дані:
	- Prompt: Додайте свої критерії для оцінки кожної пари джерело-ціль. Якщо жоден не надано, це замінюється на _"accuracy, fluency, consistency, style, grammar and spelling"_.
	- Bucket size: Кількість одиниць перекладу для обробки в одному запиті. (Див. окремий розділ)
	- Source and Target languages: За замовчуванням ми отримуємо ці значення з заголовка XLIFF. Ви можете надати інші значення, не потрібно використовувати специфічний формат.
	- Threshold: значення між 0-10.
	- Condition: Критерії для фільтрації сегментів, цільовий стан яких буде змінено.
	- New Target State: значення для оновлення цільового стану для відфільтрованих одиниць перекладу.

    Вихідні дані:
	- Average Score: агрегована оцінка всіх оцінок на рівні сегментів.
	- Updated XLIFF file: оцінка на рівні сегмента додана до атрибута extradata та оновлений цільовий стан, коли це вказано.

> Промпт, який використовується в цій дії: "Your input is going to be a group of sentences in `source language` and their translation into `target language`. Only provide as output the ID of the sentence and the score number. The score number is a score from 1 to 10 assessing the quality of the translation, considering the following criteria: `Criteria provided via Prompt input`."

Наприклад, налаштування на зображенні нижче призведуть до того, що всі сегменти з оцінкою нижче або рівною 6 матимуть оновлений цільовий стан до "needs-review-translation".

![OpenAIOptionalInput](https://raw.githubusercontent.com/bb-io/OpenAI/main/image/README/OpenAIOptionalInput.png)

- **Post-edit XLIFF file** Оновлює ціл